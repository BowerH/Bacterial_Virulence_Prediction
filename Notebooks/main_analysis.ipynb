{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Imports\n",
    "\n",
    "# !pip install pandas numpy matplotlib tensorflow scikit-learn transformers biopython pyarrow\n",
    "# !wget https://git.scicore.unibas.ch/schwede/openstructure/-/raw/master/scripts/download_alphafold_params.sh\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install biopython\n",
    "# !pip install scikit-learn\n",
    "# !pip install matplotlib\n",
    "# !pip install tensorflow\n",
    "# !pip install transformers\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Set global configurations\n",
    "DATA_DIR = \"Data/\"\n",
    "OUTPUT_DIR = \"Results/\"\n",
    "MODEL_DIR = \"Models/\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Data Preparation/Processing\n",
    "\n",
    "from preprocess import clean_sequence, ProtBERTEmbedder\n",
    "\n",
    "# Load raw datasets (VFDB, MvirDB, UniProt)\n",
    "vfdb_path = os.path.join(DATA_DIR, \"raw/vfdb_sequences.fasta\")\n",
    "uniprot_path = os.path.join(DATA_DIR, \"raw/uniprot_ecoli.csv\")\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "vfdb_df = pd.read_csv(os.path.join(DATA_DIR, \"processed/vfdb_cleaned.csv\"))\n",
    "uniprot_df = pd.read_csv(os.path.join(DATA_DIR, \"processed/uniprot_cleaned.csv\"))\n",
    "\n",
    "# Combine datasets and shuffle\n",
    "full_df = pd.concat([vfdb_df, uniprot_df]).sample(frac=1).reset_index(drop=True)\n",
    "print(f\"Combined dataset size: {full_df.shape}\")\n",
    "\n",
    "# Generate ProtBERT embeddings (if not already generated)\n",
    "embedder = ProtBERTEmbedder()\n",
    "if not os.path.exists(os.path.join(DATA_DIR, \"processed/sequence_embeddings.parquet\")):\n",
    "    print(\"Generating sequence embeddings...\")\n",
    "    embeddings = [embedder.embed(seq) for seq in full_df['sequence']]\n",
    "    embedding_df = pd.DataFrame(embeddings)\n",
    "    embedding_df['label'] = full_df['label']\n",
    "    embedding_df.to_parquet(os.path.join(DATA_DIR, \"processed/sequence_embeddings.parquet\"))\n",
    "else:\n",
    "    print(\"Loading precomputed embeddings...\")\n",
    "    embedding_df = pd.read_parquet(os.path.join(DATA_DIR, \"processed/sequence_embeddings.parquet\"))\n",
    "\n",
    "print(\"Data preprocessing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run alpha fold, the sequences must be in fasta format WITHOUT headers.\n",
    "MUST have a100 chip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Protien Structure Prediction ########\n",
    "\n",
    "print(\"Protein structure prediction is handled externally using AlphaFold.\")\n",
    "structure_features_path = os.path.join(DATA_DIR, \"processed/structural_features.csv\")\n",
    "structure_features = pd.read_csv(structure_features_path)\n",
    "\n",
    "print(f\"Loaded structural features from {structure_features_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Training ####\n",
    "\n",
    "from train_model import build_ensemble_model\n",
    "\n",
    "# Load sequence and structural features\n",
    "X_seq = embedding_df.drop(columns=['label']).values\n",
    "X_struct = structure_features.drop(columns=['label']).values\n",
    "y = embedding_df['label'].values\n",
    "\n",
    "X_seq = np.expand_dims(X_seq, axis=-1)  # Reshape for CNN input\n",
    "X_struct = X_struct.reshape((-1, 64, 64, 1))  # Adjust based on your structural feature dimensions\n",
    "\n",
    "print(f\"Sequence input shape: {X_seq.shape}\")\n",
    "print(f\"Structural input shape: {X_struct.shape}\")\n",
    "\n",
    "# Train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(X_seq_train, X_seq_test,\n",
    " X_struct_train, X_struct_test,\n",
    " y_train, y_test) = train_test_split(X_seq, X_struct, y, test_size=0.2, stratify=y)\n",
    "\n",
    "model = build_ensemble_model(seq_input_shape=X_seq.shape[1:], struct_input_shape=X_struct.shape[1:])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    [X_seq_train, X_struct_train], y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=10),\n",
    "        tf.keras.callbacks.ModelCheckpoint(os.path.join(MODEL_DIR, \"best_model.h5\"), save_best_only=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save(os.path.join(MODEL_DIR, \"final_model.h5\"))\n",
    "print(\"Model training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some visualizations of the model performance\n",
    "\n",
    "# ROC curve\n",
    "def plot_roc_curve(y_true, y_pred):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC={roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'roc_curve.png'))\n",
    "    plt.close()\n",
    "\n",
    "y_pred = model.predict([X_seq_test, X_struct_test]).ravel()\n",
    "plot_roc_curve(y_test, y_pred)\n",
    "\n",
    "y_pred_class = (y_pred > 0.5).astype(int)\n",
    "report = classification_report(y_test, y_pred_class)\n",
    "print(report)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_class)\n",
    "plt.imshow(cm, cmap='Blues', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'confusion_matrix.png'))\n",
    "plt.close()\n",
    "\n",
    "# Results Evaluation graph"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
